{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy-Shi/Networks_2_Vaccines/blob/main/Two_Vaccines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA_qQY-h8rAL"
      },
      "source": [
        "## 2-Layer Vaccine Model with Informtion, Cognition/Epidemic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install hypernetx"
      ],
      "metadata": {
        "id": "qKH-eWCwAM7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "dE2Pb1bIAT25"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hypernetx as hnx"
      ],
      "metadata": {
        "id": "fDslKBxQAUjN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fan2mZxpB3Up"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import math as math\n",
        "from math import log\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3qvT8MAI8VEs"
      },
      "outputs": [],
      "source": [
        "# Generate Degree Sequence\n",
        "def generate_degree_sequence(n, gamma, kmin):\n",
        "    # Generate a random set from the power law distribution\n",
        "    u = np.random.uniform(size=n)\n",
        "    degrees = np.ceil((1.0 - u) ** (-1.0 / (gamma - 1.0)))\n",
        "\n",
        "    # Adjust degrees based on the minimum and maximum degree values\n",
        "    kmax = int(np.sqrt(n))\n",
        "    #kmax = int(((gamma-1)/(gamma-2) * n )** (1/gamma))  # max degree\n",
        "    # kmax = int(1.5*n**(1/4)) # max degree allowed is 1.5*n^(1/4)\n",
        "    degrees = degrees[(degrees >= kmin) & (degrees <= kmax)].astype(int)\n",
        "\n",
        "    # Truncate or pad the sequence to match the length specified\n",
        "    if len(degrees) >= n:\n",
        "        degrees = degrees[:n]\n",
        "    else:\n",
        "        degrees = np.concatenate((degrees, np.full(n - len(degrees), kmin)))\n",
        "\n",
        "    return degrees.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign Thresholds\n",
        "# Defines the parameters to be used\n",
        "mu = 0.1\n",
        "sigma = 0.05\n",
        "\n",
        "# Function to assign thresholds to the individual nodes\n",
        "def assign_thresholds(hypergraph, mu, sigma):\n",
        "    NV = hypergraph.order()\n",
        "    Ltre = {}\n",
        "\n",
        "    for node in hypergraph.nodes():\n",
        "          # Uniform distribution: #\n",
        "          #Ltre[node] = np.random.uniform()\n",
        "          # Normal distrution\n",
        "          while True:\n",
        "              threshold = random.gauss(mu, sigma)\n",
        "              if 0 < threshold < 1:\n",
        "                  break\n",
        "          Ltre[node] = threshold\n",
        "\n",
        "    return Ltre"
      ],
      "metadata": {
        "id": "DxAsnBB4z_NR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "i3rNTHw7F-6v"
      },
      "outputs": [],
      "source": [
        "def Vaccine_model(inw, ldeg_i, ltre, enw, ldeg_e, lam, alp, omega, sigma, zeta_info, zeta_epi, beta_1, beta_2, beta_3, mu, n_sample):\n",
        "\n",
        "  t_max = 1000     # Set maximum time\n",
        "  kmax_i = max (ldeg_i)     # Get maximum hyperedge degree in information layer\n",
        "  kmax_e = max (ldeg_e)     # Get maximum degree in epidemic layer\n",
        "  N = inw.order()  # Get the network size\n",
        "\n",
        "  rho_A = []  # Keep track of fraction of stilfers in information layer\n",
        "  rho_C = []   # Keep track of fraction of corrected in information layer\n",
        "  rho_V1 = []   # Keep track of fraction of vaccinated with vaccine type 1 in epidemic layer\n",
        "  rho_V2 = []   # Keep track of fraction of vaccinated with vaccine type 2 in epidemic layer\n",
        "  rho_R = []   # Keep track of fraction of recovered in epidemic layer\n",
        "\n",
        "  for i_samp in range(1, n_sample + 1):\n",
        "      t = 0                 # Initialize time, number of corrected, number of recovered\n",
        "      N_corrected = 0\n",
        "      N_recovered = 0\n",
        "      N_stifler = 0\n",
        "\n",
        "      info_states = {j: \"U\" for j in inw.nodes()}   # Initialize information and disease states\n",
        "      disease_states = {k: \"S\" for k in enw.nodes()}\n",
        "\n",
        "      gossip = []     # Create lists to store gossip and corrected individuals in information layer\n",
        "      corrected = []\n",
        "      stifler = []\n",
        "\n",
        "      rumor_node_0 = np.random.choice(list(inw.nodes()))   # Pick a random person to start misinformaiton spreading\n",
        "      info_states[rumor_node_0] = \"G\"\n",
        "      gossip.append(rumor_node_0)\n",
        "      N_gossip = 1\n",
        "      N_e_i = inw.degree(rumor_node_0)\n",
        "\n",
        "\n",
        "      susceptible = list(enw.nodes())\n",
        "      infected = []     # Create lists to store infected and recovered individuals in epidemic layer\n",
        "      recovered = []\n",
        "      vaccinated_first = []\n",
        "      vaccinated_second = []\n",
        "      N_vaccine_1 = 0\n",
        "      N_vaccine_2 = 0\n",
        "\n",
        "      ill_node_0 = np.random.choice(list(enw.nodes()))   # Pick a random person to start disease spreading\n",
        "      disease_states[ill_node_0] = \"I\"\n",
        "      infected.append(ill_node_0)\n",
        "      N_infected = 1\n",
        "      N_e_e = enw.degree(ill_node_0)\n",
        "\n",
        "      beta_max = max(beta_1,beta_2,beta_3)\n",
        "\n",
        "      while t < 150 and N_infected > 0:\n",
        "          total_rate = lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_info * (N-N_gossip) + zeta_epi * (N-N_vaccine_1) + omega * N_stifler + sigma * N_gossip\n",
        "          tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "          t += tau\n",
        "\n",
        "          if t >= t_max:\n",
        "                break\n",
        "\n",
        "          # Determine which event occurs\n",
        "          event = np.random.uniform()\n",
        "          p1 = (lam * N_e_i) / total_rate     # rumor spreading\n",
        "          p2 = (lam * N_e_i + alp * N_e_i) / total_rate  # rumor stifling (by meeting stifling neighbor threshold)\n",
        "          p3 = (lam * N_e_i + 2 * alp * N_e_i) / total_rate  # rumor stifling (by meeting gossip neighbor threshold)\n",
        "\n",
        "          p4 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e) / total_rate  # disease propagation\n",
        "          p5 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected) / total_rate  # disease recovery\n",
        "\n",
        "          p6 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_info * (N-N_gossip)) / total_rate # get vaccine 1 by information\n",
        "          p7 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_info * (N-N_gossip) + zeta_epi * (N-N_vaccine_1)) / total_rate # get vaccine 1 by cognition\n",
        "          p8 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_info * (N-N_gossip) + zeta_epi * (N-N_vaccine_1) + omega * N_stifler) / total_rate # rumor interest renewal\n",
        "\n",
        "\n",
        "          # Case 1: Rumor spreading (Pairwise Threshold)\n",
        "          if event < p1:\n",
        "                response='F'\n",
        "                while len(gossip)>0 and response =='F':\n",
        "                  gossip_node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                  draw_rn = np.random.uniform()\n",
        "                  if draw_rn < inw.degree(gossip_node)/kmax_i:\n",
        "                     response='T'\n",
        "\n",
        "                neighbors = list(inw.neighbors(gossip_node))\n",
        "                neighbor = np.random.choice(neighbors)\n",
        "                if info_states[neighbor] == \"U\":\n",
        "                          count_gossip_neighbors = sum(1 for node in inw.neighbors(neighbor) if info_states[node] == \"G\")\n",
        "                          if count_gossip_neighbors / len(list(inw.neighbors(neighbor))) >= ltre[neighbor]:\n",
        "                                info_states[neighbor] = \"G\"  # uninformed neighbor becomes gossip spreader\n",
        "                                gossip.append(neighbor)\n",
        "                                N_gossip += 1\n",
        "\n",
        "          # Case 2: Rumor stifling (by meeting corrected stiflers) (Pairwise Threshold)\n",
        "          elif event < p2:\n",
        "                response='F'\n",
        "                while len(gossip)>0 and response =='F':\n",
        "                      stifler_node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                      draw_rn = np.random.uniform()\n",
        "                      if draw_rn < inw.degree(stifler_node)/kmax_i:\n",
        "                         response='T'\n",
        "\n",
        "                neighbors = inw.neighbors(stifler_node)\n",
        "                count_stifler_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"C\")\n",
        "                if count_stifler_neighbors / len(list(neighbors)) >= ltre[stifler_node]:\n",
        "                            info_states[stifler_node] = \"A\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            stifler.append(stifler_node)\n",
        "                            N_stifler += 1\n",
        "\n",
        "          # Case 3: Rumor stifling (by meeting gossip spreaders) (Pairwise Threshold)\n",
        "          elif event < p3:\n",
        "                response='F'\n",
        "                while len(gossip)>0 and response =='F':\n",
        "                      stifler_node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                      draw_rn = np.random.uniform()\n",
        "                      if draw_rn < inw.degree(stifler_node)/kmax_i:\n",
        "                         response='T'\n",
        "\n",
        "                neighbors = inw.neighbors(stifler_node)\n",
        "                count_gossip_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"G\")\n",
        "                if count_gossip_neighbors / len(list(neighbors)) >= ltre[stifler_node]:\n",
        "                            info_states[stifler_node] = \"A\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            stifler.append(stifler_node)\n",
        "                            N_stifler += 1\n",
        "\n",
        "          # Case 4: Disease propagation\n",
        "          elif event < p4:\n",
        "              response='F'\n",
        "              while len(infected)>0 and response =='F':  #draw node until degree distribution is reached and while the infected list is not empty\n",
        "                infected_node = np.random.choice(infected) #choose an infected node proportional to the degree\n",
        "                draw_rn = np.random.uniform()\n",
        "                if draw_rn < enw.degree(infected_node)/kmax_e: # kmax_e is the global max degree\n",
        "                  response='T'\n",
        "              neighbors = list(enw.neighbors(infected_node))\n",
        "              #susceptible_or_vaccinated_neighbors = [n for n in neighbors if (disease_states[n] == \"S\" or disease_states[n] == \"V1\" or disease_states[n] == \"V2\")]\n",
        "\n",
        "\n",
        "              target_node = np.random.choice(neighbors)\n",
        "              if disease_states[target_node] == \"S\" or disease_states[target_node] == \"V1\" or disease_states[target_node] == \"V2\":\n",
        "                  if disease_states[target_node] == \"V1\":\n",
        "                      beta_correct = beta_2\n",
        "                  elif disease_states[target_node] == \"V2\":\n",
        "                      beta_correct = beta_3\n",
        "                  else:\n",
        "                      beta_correct = beta_1\n",
        "\n",
        "                  draw_rn = np.random.uniform()\n",
        "                  if draw_rn < beta_correct/beta_max:\n",
        "                      disease_states[target_node] = \"I\"\n",
        "                      infected.append(target_node)\n",
        "                      N_infected += 1\n",
        "                      N_e_e += enw.degree(target_node)\n",
        "\n",
        "          # Case 5: Disease recovery\n",
        "          elif event < p5:\n",
        "                recovered_node = np.random.choice(infected)\n",
        "                disease_states[recovered_node] = \"R\"\n",
        "                infected.remove(recovered_node)\n",
        "                recovered.append(recovered_node)\n",
        "                N_infected -= 1\n",
        "                N_recovered += 1\n",
        "                N_e_e -= enw.degree(recovered_node)\n",
        "\n",
        "          # Case 6: Get vaccine 1 based on information layer\n",
        "          # rate = zeta_info * (1 - n_G / k_info)\n",
        "          elif event < p6:\n",
        "            if len(susceptible) > 0:\n",
        "                node_to_vaccinate = np.random.choice(susceptible)\n",
        "                n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_vaccinate)))\n",
        "                k_info = len(list(inw.neighbors(node_to_vaccinate)))\n",
        "                if np.random.uniform() < zeta_info * (1 - n_G / k_info):\n",
        "                        disease_states[node_to_vaccinate] = \"V1\"\n",
        "                        susceptible.remove(node_to_vaccinate)\n",
        "                        vaccinated_first.append(node_to_vaccinate)\n",
        "                        N_vaccine_1 += 1\n",
        "\n",
        "\n",
        "          # Case 7: Get vaccine 1 based on vaccination level\n",
        "          # rate = zeta_epi * (1 - n_V1 / k_epi)\n",
        "          # n_V1 is the vaccinated with vaccine 1\n",
        "          # while k_epi is the total neighbor count on the epidemics layer\n",
        "          elif event < p7:\n",
        "            if len(susceptible) > 0:\n",
        "                node_to_vaccinate = np.random.choice(susceptible)\n",
        "                n_V1 = sum(1 for node in filter(lambda x: disease_states[x] == \"V1\", enw.neighbors(node_to_vaccinate)))\n",
        "                k_epi = len(list(enw.neighbors(node_to_vaccinate)))\n",
        "                if np.random.uniform() < zeta_epi * (1 - n_V1 / k_epi):\n",
        "                        disease_states[node_to_vaccinate] = \"V1\"\n",
        "                        susceptible.remove(node_to_vaccinate)\n",
        "                        vaccinated_first.append(node_to_vaccinate)\n",
        "                        N_vaccine_1 += 1\n",
        "\n",
        "          # Case 8: Rumor interest renewal\n",
        "          elif event < p8:\n",
        "            if len(stifler) > 0:\n",
        "                  stifler_node = np.random.choice(stifler)\n",
        "                  info_states[stifler_node] = \"U\"\n",
        "                  stifler.remove(stifler_node)\n",
        "                  N_stifler -= 1\n",
        "\n",
        "          # Case 9: Correction of rumor\n",
        "          else:\n",
        "            if len(gossip)>0:\n",
        "                node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                info_states[node] = \"C\"\n",
        "                N_gossip -= 1\n",
        "                gossip.remove(node)\n",
        "                corrected.append(node)\n",
        "                N_corrected += 1\n",
        "                N_e_i -= inw.degree(node)\n",
        "\n",
        "      if N_infected == 0:\n",
        "          stifler_frac = N_stifler / N\n",
        "          corrected_frac = N_corrected / N\n",
        "          vaccine_1_frac = N_vaccine_1 / N\n",
        "          vaccine_2_frac = N_vaccine_2 /N\n",
        "          recovered_frac = N_recovered / N\n",
        "          rho_A.append(stifler_frac)\n",
        "          rho_C.append(corrected_frac)\n",
        "          rho_V1.append(vaccine_1_frac)\n",
        "          rho_V2.append(vaccine_2_frac)\n",
        "          rho_R.append(recovered_frac)\n",
        "          #print(\"corrected_frac\", corrected_frac, \"recovered_frac\", recovered_frac)\n",
        "\n",
        "  if len(rho_A) > 0 and len(rho_C) > 0 and len(rho_V1) > 0 and len(rho_V2) > 0 and len(rho_R) > 0:\n",
        "      ave_rho_A = sum(rho_A) / len(rho_A)\n",
        "      avg_rho_C = sum(rho_C) / len(rho_C)\n",
        "      avg_rho_V1 = sum(rho_V1) / len(rho_V1)\n",
        "      avg_rho_V2 = sum(rho_V2) / len(rho_V2)\n",
        "      avg_rho_R = sum(rho_R) / len(rho_R)\n",
        "  else:\n",
        "      avg_rho_R = 0\n",
        "\n",
        "  return avg_rho_C, avg_rho_V1, avg_rho_V2, avg_rho_R\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_NnnBI-BZpo",
        "outputId": "d184b513-d54e-4ff3-93d6-f63c60c8452f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree Sequence:  [9, 4, 8, 4, 3, 9, 4, 3, 4, 3, 7, 7, 3, 7, 3, 4, 6, 3, 4, 3, 9, 7, 3, 4, 3, 3, 3, 4, 3, 3, 5, 3, 5, 3, 3, 6, 6, 4, 4, 12, 4, 3, 3, 3, 6, 3, 3, 7, 3, 4, 3, 12, 3, 3, 7, 4, 4, 3, 4, 4, 4, 3, 3, 3, 16, 3, 4, 5, 3, 5, 3, 3, 4, 3, 3, 5, 3, 3, 4, 4, 4, 4, 3, 5, 3, 5, 3, 18, 5, 18, 6, 4, 3, 9, 3, 11, 5, 6, 5, 6, 3, 3, 3, 3, 9, 3, 12, 3, 5, 3, 4, 3, 5, 11, 21, 3, 3, 8, 4, 4, 3, 4, 3, 4, 3, 3, 4, 5, 7, 4, 6, 3, 3, 4, 4, 4, 4, 3, 5, 4, 5, 3, 6, 11, 4, 3, 3, 5, 4, 5, 3, 4, 8, 6, 4, 3, 7, 3, 20, 5, 3, 3, 3, 3, 11, 7, 7, 7, 16, 16, 5, 4, 4, 5, 5, 4, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        }
      ],
      "source": [
        "n = 500  # Number of nodes\n",
        "\n",
        "# Information Layer\n",
        "gamma_i = 2.5\n",
        "kmin_i = 3\n",
        "ldeg_i = generate_degree_sequence(n, gamma_i, kmin_i)\n",
        "print(\"Degree Sequence: \", ldeg_i)\n",
        "inw = nx.configuration_model(ldeg_i)\n",
        "ltre = assign_thresholds(inw, 0.10, 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Epidemic Layer\n",
        "gamma_e = 4.0\n",
        "kmin_e = 3\n",
        "ldeg_e = generate_degree_sequence(n, gamma_e, kmin_e)\n",
        "print(\"Degree Sequence: \", ldeg_e)\n",
        "enw = nx.configuration_model(ldeg_e)\n",
        "k = ((gamma_e-1)/(gamma_e-2))*(kmin_e) #<k>\n",
        "k2 =((gamma_e-1)/(gamma_e-3))*((kmin_e)**2) #<k^2>\n",
        "division_factor = (k2-k)/k # division factor to compute beta_max(<k^2>-<k>)/<k>\n",
        "print([\"<k>: \", k, \"<k^2>: \", k2,\"(<k^2>-<k>)/<k>: \",  division_factor])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQRjsAP3BC8I",
        "outputId": "1b828955-6874-4041-929f-237ca8a81909"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree Sequence:  [3, 3, 3, 3, 3, 3, 4, 3, 6, 4, 3, 3, 8, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 8, 3, 4, 3, 3, 4, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 4, 13, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "['<k>: ', 4.5, '<k^2>: ', 27.0, '(<k^2>-<k>)/<k>: ', 5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGOHKVGoPuRu",
        "outputId": "99242db4-b611-4bbc-d67f-eaafd1d06acd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "lam = 1/3 # gossip spreading rate\n",
        "alp = 1/3 # gossip stifling rate\n",
        "omega = 1/5 # gossip renewal rate\n",
        "sigma = 0 # correction rate of misinformation\n",
        "\n",
        "zeta_info = 0.2\n",
        "zeta_epi = 0.2\n",
        "\n",
        "mu = 0.2\n",
        "R0 = 4.0 #4.0 (assume a COVID19-like disease for the reproduction number) 2.0 # reproduction number\n",
        "beta_1 = R0 * mu / division_factor\n",
        "beta_2 = beta_1*(1-0.76)\n",
        "beta_3 = beta_1*(1-0.94)\n",
        "\n",
        "n_sample = 100\n",
        "\n",
        "# Vary V1 percentage\n",
        "V1_percentage_values = np.arange(0.1, 1.0, 0.1)\n",
        "\n",
        "# Initialize the result array\n",
        "results_rho_R = np.zeros(len(V1_percentage_values))\n",
        "\n",
        "# Iterate over V1 percentage\n",
        "for i in enumerate(V1_percentage_values):\n",
        "        avg_rho_R = Vaccine_model(inw, ldeg_i, ltre, enw, ldeg_e, lam, alp, omega, sigma, zeta_info, zeta_epi, beta_1, beta_2, beta_3, mu, n_sample)\n",
        "        results_rho_R[i] = avg_rho_R\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "ax.plot(V1_percentage_values, results_rho_R)\n",
        "ax.set_xlabel('Fraction of Type 1 Vaccine Given', fontsize = 16)\n",
        "ax.set_ylabel('Attack Rate', fontsize = 16)\n",
        "#ax.set_yscale('log')  # Set y-axis to be logarithmic\n",
        "plt.rc('xtick', labelsize=16)\n",
        "plt.rc('ytick', labelsize=16)\n",
        "ax.legend(fontsize = 16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "laJlQbtX9Lg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmPqYLjYj734eyk1SS2Xit",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}